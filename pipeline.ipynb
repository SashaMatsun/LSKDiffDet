{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check pytorch installation: \n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusiondet imports\n",
    "import sys\n",
    "sys.path.append('DiffusionDet')\n",
    "\n",
    "from diffusiondet.util.model_ema import add_model_ema_configs, may_build_model_ema, may_get_ema_checkpointer, EMAHook, \\\n",
    "    apply_model_ema_and_restore, EMADetectionCheckpointer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "from train_net import Trainer\n",
    "from diffusiondet import add_diffusiondet_config\n",
    "from diffusiondet.util.model_ema import add_model_ema_configs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register datasets\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"iSAID_train\", {}, \n",
    "                        \"/share/sda/aleksandrmatsun/iSAID/iSAID_patches/train/instancesonly_filtered_train.json\",\n",
    "                        \"/share/sda/aleksandrmatsun/iSAID/iSAID_patches/train/images/\")\n",
    "register_coco_instances(\"iSAID_val\", {}, \n",
    "                        \"/share/sda/aleksandrmatsun/iSAID/iSAID_patches/val/instancesonly_filtered_val.json\",\n",
    "                        \"/share/sda/aleksandrmatsun/iSAID/iSAID_patches/val/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from detectron2.data.transforms import RandomFlip as D2RandomFlip\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import DatasetMapper\n",
    "\n",
    "# creating custom augmentation classes compatible with Detectron2 framework\n",
    "\n",
    "class MyCustomResize(T.Augmentation):\n",
    "    def get_transform(self, image):\n",
    "        old_h, old_w = image.shape[:2]\n",
    "        new_h, new_w = int(old_h * np.random.rand()), int(old_w * 1.5)\n",
    "        return T.ResizeTransform(old_h, old_w, new_h, new_w)\n",
    "\n",
    "class MyCustomRandomFlip(T.Augmentation):\n",
    "    def __init__(self, horizontal=True, vertical=False):\n",
    "        super().__init__()\n",
    "        self.horizontal = horizontal\n",
    "        self.vertical = vertical\n",
    "\n",
    "    def get_transform(self, image):\n",
    "        flip_transform = D2RandomFlip(horizontal=self.horizontal, vertical=self.vertical)\n",
    "        return flip_transform.get_transform(image)\n",
    "\n",
    "class AlbumentationsTransform(T.Transform):\n",
    "    def __init__(self, albumentations_transform, p=1.0):\n",
    "        super().__init__()\n",
    "        self.albumentations_transform = albumentations_transform\n",
    "        self.p = p\n",
    "\n",
    "    def apply_image(self, image):\n",
    "        if self.albumentations_transform and random.random() < self.p:\n",
    "            transformed = self.albumentations_transform(image=image)\n",
    "            if transformed is not None:\n",
    "                return transformed['image']\n",
    "        return image\n",
    "\n",
    "class MyAlbumentations(T.Augmentation):\n",
    "    def __init__(self, p=1.0):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.transform = None\n",
    "        try:\n",
    "            import albumentations as A\n",
    "\n",
    "            T = [\n",
    "                A.Blur(p=0.01),\n",
    "                A.MedianBlur(p=0.01),\n",
    "                A.ToGray(p=0.01),\n",
    "                A.CLAHE(p=0.01),\n",
    "                A.RandomBrightnessContrast(p=0.0),\n",
    "                A.RandomGamma(p=0.0),\n",
    "                A.ImageCompression(quality_lower=75, p=0.0)]  # transforms\n",
    "            self.transform = A.Compose(T, bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "        except ImportError:  # package not installed, skip\n",
    "            pass\n",
    "\n",
    "    def get_transform(self, image):\n",
    "        return AlbumentationsTransform(self.transform, self.p)\n",
    "\n",
    "def register_new_dataset():\n",
    "\n",
    "    dataset_mapper = DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "        MyCustomResize(),\n",
    "        MyCustomRandomFlip(horizontal=True, vertical=False),\n",
    "        MyAlbumentations(p=1.0)  # Add custom Albumentations augmentation\n",
    "    ])\n",
    "    iSAID_train_metadata = MetadataCatalog.get(\"iSAID_train\")\n",
    "    iSAID_train_metadata.dataset_mapper = dataset_mapper\n",
    "\n",
    "    return iSAID_train_metadata, MetadataCatalog.get(\"iSAID_val\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone preparing\n",
    "from detectron2.modeling import BACKBONE_REGISTRY, Backbone, ShapeSpec\n",
    "from mmrotate.models.builder import ROTATED_BACKBONES, ROTATED_NECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone class\n",
    "@BACKBONE_REGISTRY.register()\n",
    "class LSKBackbone(Backbone):\n",
    "  def __init__(self, cfg, input_shape):\n",
    "    super().__init__()\n",
    "    # backbone definition\n",
    "    self.bb = ROTATED_BACKBONES.get('LSKNet')(embed_dims=[64, 128, 320, 512], drop_rate=0.1, drop_path_rate=0.1, depths=[2,2,4,2])\n",
    "    self.neck = ROTATED_NECKS.get('FPN')(in_channels=[64, 128, 320, 512],\n",
    "        out_channels=256,\n",
    "        num_outs=5)\n",
    "\n",
    "  def forward(self, image):\n",
    "    out = self.bb(image)\n",
    "    out = self.neck(out)\n",
    "    return {\n",
    "      'p2' : out[0],\n",
    "      'p3' : out[1],\n",
    "      'p4' : out[2],\n",
    "      'p5' : out[3],\n",
    "      'p6' : out[4],\n",
    "    }\n",
    "\n",
    "  def output_shape(self):\n",
    "    return {\n",
    "      'p2': ShapeSpec(channels=256, stride=4),\n",
    "      'p3': ShapeSpec(channels=256, stride=8),\n",
    "      'p4': ShapeSpec(channels=256, stride=16),\n",
    "      'p5': ShapeSpec(channels=256, stride=32),\n",
    "      'p6': ShapeSpec(channels=256, stride=64),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "# config preparation\n",
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = '/home/aleksandrmatsun/projectron/output_best' # the output directory should be changed accordingly\n",
    "add_diffusiondet_config(cfg)\n",
    "add_model_ema_configs(cfg)\n",
    "cfg.merge_from_file(\"/home/aleksandrmatsun/projectron/DiffusionDet/configs/diffdet.coco.res50.yaml\") # the config from DiffusionDet to be merged with\n",
    "cfg.DATASETS.TRAIN = (\"iSAID_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.DEVICE = \"cuda:0\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.00005  # small learning rate due to DiffusionDet properties\n",
    "cfg.SOLVER.MAX_ITER = 100000\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 10000\n",
    "cfg.MODEL.DiffusionDet.NUM_CLASSES = 15\n",
    "cfg.MODEL.DiffusionDet.NUM_PROPOSALS = 700\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.25, 0.75, 2.0, 4.0]] # setting custom aspect ratios\n",
    "cfg.MODEL.BACKBONE.NAME = \"LSKBackbone\" # setting the LSKNet as backbone\n",
    "\n",
    "cfg.MODEL.BACKBONE.FREEZE_AT = 0 # this line is redundant, but kept for consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_new_dataset() # applying custom augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) # creating the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.load('/home/aleksandrmatsun/projectron/weights/lsk_s_backbone-e9d2e551.pth') # weights for backbone (pretrained on imagenet)\n",
    "w2 = torch.load('/home/aleksandrmatsun/projectron/weights/diffdet_coco_res101.pth') # weights for heads (pretrained on COCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_heads = {k:w2['model'][k] for k in w2['model'] if (not k.startswith('backbone') and k.find('class_logits')==-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the neck of the model is initialized from scratch, due to unavailability of any fitting weights\n",
    "trainer.model.backbone.bb.load_state_dict(w['state_dict'], strict=False) \n",
    "trainer.model.load_state_dict(w_heads, strict=False)\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"iSAID_test\", {}, \n",
    "                        \"/share/sda/aleksandrmatsun/iSAID/iSAID_patches/test/test_info.json\",\n",
    "                        \"/share/sda/aleksandrmatsun/iSAID/iSAID_patches/test/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join('/home/aleksandrmatsun/projectron/output_best/model_0099999.pth') # weights to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATASETS.TEST = (\"iSAID_val\",)  # for evaluation on validation subset\n",
    "# cfg.DATASETS.TEST = (\"iSAID_test\",) # for evaluation on test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Trainer.build_model(cfg)\n",
    "kwargs = may_get_ema_checkpointer(cfg, m)\n",
    "cfg.MODEL_EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectionCheckpointer(m, save_dir=cfg.OUTPUT_DIR, **kwargs).resume_or_load(cfg.MODEL.WEIGHTS,\n",
    "                                                                                           resume=True) # checkpointer creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Trainer.ema_test(cfg, m) # no EMA is actually used, this function runs regular evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:05:54) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf115790215a42b6075b8b12062c482775e0160ef13c5413b3fb22ea5ec26be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
